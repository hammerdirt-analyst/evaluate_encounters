[2025-07-14 01:13:39] [classifiers] [INFO]: Saving logs to : 'logs/classifiers.log'
[2025-07-14 01:13:56] [Run script] [INFO]: New test: classification
[2025-07-14 01:13:56] [classifiers] [INFO]: Reading data/g70_obs_2015_2022.csv
[2025-07-14 01:13:56] [Run script] [INFO]: Evaluating count data split by date
[2025-07-14 01:13:56] [classifiers] [INFO]: Running classifier pipeline for : dict_keys(['LogisticRegression', 'MultinomialNB', 'RandomForestClassifier', 'XGBClassifier'])
[2025-07-14 01:13:56] [classifiers] [INFO]: Tuning models on thresholds: [1, 2, 3], target column: quantity and split by: {'method': 'date', 'date_column': 'date', 'date_split': '2022-01-01'}
[2025-07-14 01:13:56] [classifiers] [INFO]: Full evaluation on the range of 1 - 51
[2025-07-14 01:13:56] [classifiers] [INFO]: Tuning models for classification.
[2025-07-14 01:13:56] [classifiers] [INFO]: Tuning model: LogisticRegression
[2025-07-14 01:13:59] [classifiers] [INFO]: Threshold 1, AUC: 0.671, Params: {'clf__C': 0.01}
[2025-07-14 01:14:00] [classifiers] [INFO]: Threshold 2, AUC: 0.677, Params: {'clf__C': 0.01}
[2025-07-14 01:14:00] [classifiers] [INFO]: Threshold 3, AUC: 0.711, Params: {'clf__C': 0.01}
[2025-07-14 01:14:00] [classifiers] [INFO]: Tuning model: MultinomialNB
[2025-07-14 01:14:00] [classifiers] [INFO]: Threshold 1, AUC: 0.671, Params: {'clf__alpha': 0.1}
[2025-07-14 01:14:00] [classifiers] [INFO]: Threshold 2, AUC: 0.677, Params: {'clf__alpha': 0.1}
[2025-07-14 01:14:00] [classifiers] [INFO]: Threshold 3, AUC: 0.711, Params: {'clf__alpha': 0.1}
[2025-07-14 01:14:00] [classifiers] [INFO]: Tuning model: RandomForestClassifier
[2025-07-14 01:14:02] [classifiers] [INFO]: Threshold 1, AUC: 0.708, Params: {'clf__max_depth': 8, 'clf__n_estimators': 100}
[2025-07-14 01:14:04] [classifiers] [INFO]: Threshold 2, AUC: 0.677, Params: {'clf__max_depth': 4, 'clf__n_estimators': 100}
[2025-07-14 01:14:06] [classifiers] [INFO]: Threshold 3, AUC: 0.711, Params: {'clf__max_depth': 4, 'clf__n_estimators': 100}
[2025-07-14 01:14:06] [classifiers] [INFO]: Tuning model: XGBClassifier
[2025-07-14 01:14:06] [classifiers] [INFO]: Threshold 1, AUC: 0.671, Params: {'clf__max_depth': 3, 'clf__n_estimators': 100, 'clf__scale_pos_weight': 1}
[2025-07-14 01:14:07] [classifiers] [INFO]: Threshold 2, AUC: 0.677, Params: {'clf__max_depth': 3, 'clf__n_estimators': 100, 'clf__scale_pos_weight': 1}
[2025-07-14 01:14:07] [classifiers] [INFO]: Threshold 3, AUC: 0.711, Params: {'clf__max_depth': 3, 'clf__n_estimators': 100, 'clf__scale_pos_weight': 1}
[2025-07-14 01:14:07] [classifiers] [INFO]: Saved tuning_summary to data/test_results/date_split_quantity_tuning_summary.csv.
[2025-07-14 01:14:07] [classifiers] [INFO]: Summary results for tuning:
|    | model                  |        1 |        2 |        3 |
|---:|:-----------------------|---------:|---------:|---------:|
|  0 | LogisticRegression     | 0.671393 | 0.676689 | 0.710625 |
|  1 | MultinomialNB          | 0.671393 | 0.676689 | 0.710625 |
|  2 | RandomForestClassifier | 0.708082 | 0.676689 | 0.710625 |
|  3 | XGBClassifier          | 0.671393 | 0.676689 | 0.710625 |
[2025-07-14 01:14:07] [classifiers] [INFO]: Saving results to data/test_results
[2025-07-14 01:14:07] [classifiers] [INFO]: Selecting best model
[2025-07-14 01:14:07] [classifiers] [INFO]: Selected model: RandomForestClassifier with params {'max_depth': 4, 'n_estimators': 100}
[2025-07-14 01:14:07] [classifiers] [INFO]: Applying model to each threshold
[2025-07-14 01:14:07] [classifiers] [INFO]: Evaluating model: <class 'sklearn.ensemble._forest.RandomForestClassifier'>
[2025-07-14 01:14:15] [classifiers] [WARNING]: Threshold 35: not enough class variation.
[2025-07-14 01:14:15] [classifiers] [WARNING]: Threshold 36: not enough class variation.
[2025-07-14 01:14:15] [classifiers] [WARNING]: Threshold 37: not enough class variation.
[2025-07-14 01:14:15] [classifiers] [WARNING]: Threshold 38: not enough class variation.
[2025-07-14 01:14:15] [classifiers] [WARNING]: Threshold 39: not enough class variation.
[2025-07-14 01:14:15] [classifiers] [WARNING]: Threshold 40: not enough class variation.
[2025-07-14 01:14:15] [classifiers] [WARNING]: Threshold 41: not enough class variation.
[2025-07-14 01:14:15] [classifiers] [WARNING]: Threshold 42: not enough class variation.
[2025-07-14 01:14:15] [classifiers] [WARNING]: Threshold 43: not enough class variation.
[2025-07-14 01:14:15] [classifiers] [WARNING]: Threshold 44: not enough class variation.
[2025-07-14 01:14:15] [classifiers] [WARNING]: Threshold 45: not enough class variation.
[2025-07-14 01:14:15] [classifiers] [WARNING]: Threshold 46: not enough class variation.
[2025-07-14 01:14:15] [classifiers] [WARNING]: Threshold 47: not enough class variation.
[2025-07-14 01:14:15] [classifiers] [WARNING]: Threshold 48: not enough class variation.
[2025-07-14 01:14:15] [classifiers] [WARNING]: Threshold 49: not enough class variation.
[2025-07-14 01:14:15] [classifiers] [WARNING]: Threshold 50: not enough class variation.
[2025-07-14 01:14:15] [classifiers] [WARNING]: Threshold 51: not enough class variation.
[2025-07-14 01:14:15] [classifiers] [INFO]: Summarizing region-level probabilities
[2025-07-14 01:14:15] [classifiers] [INFO]: The first rows of the regional predictions dataframe, number of rows = 34
 |    |   threshold |   weighted_mean_probability |      auc |   accuracy |   Grand lac |   Haut lac |   Petit lac |
|---:|------------:|----------------------------:|---------:|-----------:|------------:|-----------:|------------:|
|  0 |           1 |                  0.441663   | 0.615132 |   0.591837 |   0.400839  |  0.728123  |   0.258094  |
|  1 |           2 |                  0.286969   | 0.572704 |   0.612245 |   0.231609  |  0.571789  |   0.130164  |
|  2 |           3 |                  0.19692    | 0.537724 |   0.785714 |   0.117266  |  0.493528  |   0.0719256 |
|  3 |           4 |                  0.169859   | 0.567901 |   0.826531 |   0.0947605 |  0.416385  |   0.0814529 |
|  4 |           5 |                  0.137742   | 0.494318 |   0.897959 |   0.055478  |  0.375242  |   0.0698298 |
|  5 |           6 |                  0.117795   | 0.627943 |   0.928571 |   0.0583781 |  0.304865  |   0.0549411 |
|  6 |           7 |                  0.087685   | 0.360215 |   0.94898  |   0.018547  |  0.258207  |   0.0564612 |
|  7 |           8 |                  0.0826595  | 0.360215 |   0.94898  |   0.0176383 |  0.254432  |   0.0431579 |
|  8 |           9 |                  0.0630091  | 0.360215 |   0.94898  |   0         |  0.219341  |   0.0337301 |
|  9 |          10 |                  0.0615099  | 0.360215 |   0.94898  |   0         |  0.205683  |   0.0404286 |
| 10 |          11 |                  0.0543919  | 0.360215 |   0.94898  |   0         |  0.180762  |   0.0367449 |
| 11 |          12 |                  0.0486574  | 0.360215 |   0.94898  |   0         |  0.161474  |   0.0330761 |
| 12 |          13 |                  0.041522   | 0.450877 |   0.969388 |   0         |  0.132538  |   0.0328975 |
| 13 |          14 |                  0.0430476  | 0.450877 |   0.969388 |   0         |  0.137519  |   0.0340076 |
| 14 |          15 |                  0.0440764  | 0.450877 |   0.969388 |   0         |  0.13998   |   0.0355543 |
| 15 |          16 |                  0.0341505  | 0.450877 |   0.969388 |   0         |  0.121916  |   0.0155843 |
| 16 |          17 |                  0.0344183  | 0.450877 |   0.969388 |   0         |  0.118494  |   0.019598  |
| 17 |          18 |                  0.0286965  | 0.559896 |   0.979592 |   0         |  0.096555  |   0.018331  |
| 18 |          19 |                  0.0232858  | 0.559896 |   0.979592 |   0         |  0.0735367 |   0.0191528 |
| 19 |          20 |                  0.0219893  | 0.559896 |   0.979592 |   0         |  0.0702446 |   0.0173733 |
| 20 |          21 |                  0.0200727  | 0.559896 |   0.979592 |   0         |  0.0659101 |   0.0142698 |
| 21 |          22 |                  0.0186437  | 0.559896 |   0.979592 |   0         |  0.0595734 |   0.0147155 |
| 22 |          23 |                  0.0123484  | 0.630208 |   0.979592 |   0         |  0.0504228 |   0         |
| 23 |          24 |                  0.0124182  | 0.630208 |   0.979592 |   0         |  0.0507078 |   0         |
| 24 |          25 |                  0.0130929  | 0.630208 |   0.979592 |   0         |  0.0534628 |   0         |
| 25 |          26 |                  0.0100114  | 0.630208 |   0.979592 |   0         |  0.0408801 |   0         |
| 26 |          27 |                  0.0102377  | 0.630208 |   0.979592 |   0         |  0.0418039 |   0         |
| 27 |          28 |                  0.00854061 | 0.630208 |   0.979592 |   0         |  0.0348742 |   0         |
| 28 |          29 |                  0.00896299 | 0.630208 |   0.979592 |   0         |  0.0365989 |   0         |
| 29 |          30 |                  0.00888331 | 0.630208 |   0.979592 |   0         |  0.0362735 |   0         |
| 30 |          31 |                  0.00919053 | 0.630208 |   0.979592 |   0         |  0.037528  |   0         |
| 31 |          32 |                  0.00938539 | 0.630208 |   0.979592 |   0         |  0.0383237 |   0         |
| 32 |          33 |                  0.00867172 | 0.630208 |   0.979592 |   0         |  0.0354095 |   0         |
| 33 |          34 |                  0.00854356 | 0.881443 |   0.989796 |   0         |  0.0348862 |   0         |
[2025-07-14 01:14:15] [classifiers] [INFO]: Saved summary to data/test_results/date_split_quantity_summary.csv.
[2025-07-14 01:14:15] [classifiers] [INFO]: Saved test_predictions to data/test_results/date_split_quantity_test_predictions.csv.
[2025-07-14 01:14:15] [Run script] [INFO]: Evaluating count data split randomly
[2025-07-14 01:14:15] [classifiers] [INFO]: Running classifier pipeline for : dict_keys(['LogisticRegression', 'MultinomialNB', 'RandomForestClassifier', 'XGBClassifier'])
[2025-07-14 01:14:15] [classifiers] [INFO]: Tuning models on thresholds: [1, 2, 3], target column: quantity and split by: {'method': 'random', 'test_size': 0.2}
[2025-07-14 01:14:15] [classifiers] [INFO]: Full evaluation on the range of 1 - 51
[2025-07-14 01:14:15] [classifiers] [INFO]: Tuning models for classification.
[2025-07-14 01:14:15] [classifiers] [INFO]: Tuning model: LogisticRegression
[2025-07-14 01:14:15] [classifiers] [INFO]: Threshold 1, AUC: 0.672, Params: {'clf__C': 0.01}
[2025-07-14 01:14:15] [classifiers] [INFO]: Threshold 2, AUC: 0.658, Params: {'clf__C': 0.01}
[2025-07-14 01:14:15] [classifiers] [INFO]: Threshold 3, AUC: 0.679, Params: {'clf__C': 0.01}
[2025-07-14 01:14:15] [classifiers] [INFO]: Tuning model: MultinomialNB
[2025-07-14 01:14:16] [classifiers] [INFO]: Threshold 1, AUC: 0.672, Params: {'clf__alpha': 0.1}
[2025-07-14 01:14:16] [classifiers] [INFO]: Threshold 2, AUC: 0.658, Params: {'clf__alpha': 0.1}
[2025-07-14 01:14:16] [classifiers] [INFO]: Threshold 3, AUC: 0.679, Params: {'clf__alpha': 0.1}
[2025-07-14 01:14:16] [classifiers] [INFO]: Tuning model: RandomForestClassifier
[2025-07-14 01:14:17] [classifiers] [INFO]: Threshold 1, AUC: 0.672, Params: {'clf__max_depth': 4, 'clf__n_estimators': 100}
[2025-07-14 01:14:19] [classifiers] [INFO]: Threshold 2, AUC: 0.658, Params: {'clf__max_depth': 4, 'clf__n_estimators': 100}
[2025-07-14 01:14:20] [classifiers] [INFO]: Threshold 3, AUC: 0.679, Params: {'clf__max_depth': 4, 'clf__n_estimators': 100}
[2025-07-14 01:14:20] [classifiers] [INFO]: Tuning model: XGBClassifier
[2025-07-14 01:14:21] [classifiers] [INFO]: Threshold 1, AUC: 0.672, Params: {'clf__max_depth': 3, 'clf__n_estimators': 100, 'clf__scale_pos_weight': 1}
[2025-07-14 01:14:21] [classifiers] [INFO]: Threshold 2, AUC: 0.658, Params: {'clf__max_depth': 3, 'clf__n_estimators': 100, 'clf__scale_pos_weight': 1}
[2025-07-14 01:14:22] [classifiers] [INFO]: Threshold 3, AUC: 0.679, Params: {'clf__max_depth': 3, 'clf__n_estimators': 100, 'clf__scale_pos_weight': 1}
[2025-07-14 01:14:22] [classifiers] [INFO]: Saved tuning_summary to data/test_results/random_split_quantity_tuning_summary.csv.
[2025-07-14 01:14:22] [classifiers] [INFO]: Summary results for tuning:
|    | model                  |       1 |       2 |        3 |
|---:|:-----------------------|--------:|--------:|---------:|
|  0 | LogisticRegression     | 0.67157 | 0.65825 | 0.679384 |
|  1 | MultinomialNB          | 0.67157 | 0.65825 | 0.679384 |
|  2 | RandomForestClassifier | 0.67157 | 0.65825 | 0.679384 |
|  3 | XGBClassifier          | 0.67157 | 0.65825 | 0.679384 |
[2025-07-14 01:14:22] [classifiers] [INFO]: Saving results to data/test_results
[2025-07-14 01:14:22] [classifiers] [INFO]: Selecting best model
[2025-07-14 01:14:22] [classifiers] [INFO]: Selected model: LogisticRegression with params {'C': 0.01}
[2025-07-14 01:14:22] [classifiers] [INFO]: Applying model to each threshold
[2025-07-14 01:14:22] [classifiers] [INFO]: Evaluating model: <class 'sklearn.linear_model._logistic.LogisticRegression'>
[2025-07-14 01:14:23] [classifiers] [WARNING]: Threshold 47: not enough class variation.
[2025-07-14 01:14:23] [classifiers] [WARNING]: Threshold 48: not enough class variation.
[2025-07-14 01:14:23] [classifiers] [WARNING]: Threshold 49: not enough class variation.
[2025-07-14 01:14:23] [classifiers] [WARNING]: Threshold 50: not enough class variation.
[2025-07-14 01:14:23] [classifiers] [WARNING]: Threshold 51: not enough class variation.
[2025-07-14 01:14:23] [classifiers] [INFO]: Summarizing region-level probabilities
[2025-07-14 01:14:23] [classifiers] [INFO]: The first rows of the regional predictions dataframe, number of rows = 46
 |    |   threshold |   weighted_mean_probability |      auc |   accuracy |   Grand lac |   Haut lac |   Petit lac |
|---:|------------:|----------------------------:|---------:|-----------:|------------:|-----------:|------------:|
|  0 |           1 |                  0.496729   | 0.813268 |   0.785714 |  0.479865   |  0.527815  |   0.456188  |
|  1 |           2 |                  0.338579   | 0.797286 |   0.542857 |  0.323623   |  0.36282   |   0.308583  |
|  2 |           3 |                  0.274427   | 0.782609 |   0.657143 |  0.254696   |  0.2978    |   0.250256  |
|  3 |           4 |                  0.245374   | 0.783019 |   0.757143 |  0.229946   |  0.264583  |   0.224804  |
|  4 |           5 |                  0.202587   | 0.755735 |   0.814286 |  0.183611   |  0.222227  |   0.18442   |
|  5 |           6 |                  0.155322   | 0.765794 |   0.842857 |  0.14431    |  0.167233  |   0.143861  |
|  6 |           7 |                  0.130176   | 0.700605 |   0.885714 |  0.119893   |  0.13995   |   0.121884  |
|  7 |           8 |                  0.126524   | 0.684807 |   0.9      |  0.11667    |  0.136459  |   0.117561  |
|  8 |           9 |                  0.111993   | 0.776923 |   0.928571 |  0.104597   |  0.119519  |   0.105144  |
|  9 |          10 |                  0.108366   | 0.776923 |   0.928571 |  0.101543   |  0.115328  |   0.10201   |
| 10 |          11 |                  0.0975005  | 0.776923 |   0.928571 |  0.0922936  |  0.102876  |   0.0925406 |
| 11 |          12 |                  0.0865609  | 0.776923 |   0.928571 |  0.0827876  |  0.0905267 |   0.0828403 |
| 12 |          13 |                  0.0722007  | 0.772727 |   0.942857 |  0.0685292  |  0.0754946 |   0.0695913 |
| 13 |          14 |                  0.0722007  | 0.772727 |   0.942857 |  0.0685292  |  0.0754946 |   0.0695913 |
| 14 |          15 |                  0.0722007  | 0.772727 |   0.942857 |  0.0685292  |  0.0754946 |   0.0695913 |
| 15 |          16 |                  0.0649476  | 0.768657 |   0.957143 |  0.0619706  |  0.0679246 |   0.062284  |
| 16 |          17 |                  0.061328   | 0.768657 |   0.957143 |  0.0587346  |  0.063931  |   0.0589905 |
| 17 |          18 |                  0.0468805  | 0.768657 |   0.957143 |  0.0450712  |  0.0485398 |   0.0455302 |
| 18 |          19 |                  0.03966    | 0.764706 |   0.971429 |  0.0384247  |  0.0407743 |   0.0387711 |
| 19 |          20 |                  0.0360324  | 0.764706 |   0.971429 |  0.0350465  |  0.0369134 |   0.0353382 |
| 20 |          21 |                  0.0360324  | 0.764706 |   0.971429 |  0.0350465  |  0.0369134 |   0.0353382 |
| 21 |          22 |                  0.0323766  | 0.764706 |   0.971429 |  0.0316104  |  0.0330517 |   0.0318541 |
| 22 |          23 |                  0.0251743  | 0.764706 |   0.971429 |  0.0247367  |  0.0256921 |   0.0246392 |
| 23 |          24 |                  0.0251743  | 0.764706 |   0.971429 |  0.0247367  |  0.0256921 |   0.0246392 |
| 24 |          25 |                  0.0251743  | 0.764706 |   0.971429 |  0.0247367  |  0.0256921 |   0.0246392 |
| 25 |          26 |                  0.0251743  | 0.76087  |   0.985714 |  0.0247367  |  0.0256921 |   0.0246392 |
| 26 |          27 |                  0.0251743  | 0.76087  |   0.985714 |  0.0247367  |  0.0256921 |   0.0246392 |
| 27 |          28 |                  0.0215962  | 0.76087  |   0.985714 |  0.0213054  |  0.0219577 |   0.0212096 |
| 28 |          29 |                  0.0215962  | 0.76087  |   0.985714 |  0.0213054  |  0.0219577 |   0.0212096 |
| 29 |          30 |                  0.0215962  | 0.76087  |   0.985714 |  0.0213054  |  0.0219577 |   0.0212096 |
| 30 |          31 |                  0.0215962  | 0.76087  |   0.985714 |  0.0213054  |  0.0219577 |   0.0212096 |
| 31 |          32 |                  0.0215962  | 0.76087  |   0.985714 |  0.0213054  |  0.0219577 |   0.0212096 |
| 32 |          33 |                  0.0215962  | 0.76087  |   0.985714 |  0.0213054  |  0.0219577 |   0.0212096 |
| 33 |          34 |                  0.0180106  | 0.76087  |   0.985714 |  0.0176283  |  0.0183729 |   0.0177042 |
| 34 |          35 |                  0.0144077  | 0.76087  |   0.985714 |  0.0141613  |  0.0146412 |   0.0142104 |
| 35 |          36 |                  0.0144077  | 0.76087  |   0.985714 |  0.0141613  |  0.0146412 |   0.0142104 |
| 36 |          37 |                  0.0144077  | 0.76087  |   0.985714 |  0.0141613  |  0.0146412 |   0.0142104 |
| 37 |          38 |                  0.010812   | 0.76087  |   0.985714 |  0.010672   |  0.0109445 |   0.0107    |
| 38 |          39 |                  0.010812   | 0.76087  |   0.985714 |  0.010672   |  0.0109445 |   0.0107    |
| 39 |          40 |                  0.010812   | 0.76087  |   0.985714 |  0.010672   |  0.0109445 |   0.0107    |
| 40 |          41 |                  0.010812   | 0.76087  |   0.985714 |  0.010672   |  0.0109445 |   0.0107    |
| 41 |          42 |                  0.010812   | 0.76087  |   0.985714 |  0.010672   |  0.0109445 |   0.0107    |
| 42 |          43 |                  0.010812   | 0.76087  |   0.985714 |  0.010672   |  0.0109445 |   0.0107    |
| 43 |          44 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 |  0.0072947 |   0.0071837 |
| 44 |          45 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 |  0.0072947 |   0.0071837 |
| 45 |          46 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 |  0.0072947 |   0.0071837 |
[2025-07-14 01:14:23] [classifiers] [INFO]: Saved summary to data/test_results/random_split_quantity_summary.csv.
[2025-07-14 01:14:24] [classifiers] [INFO]: Saved test_predictions to data/test_results/random_split_quantity_test_predictions.csv.
[2025-07-14 01:14:24] [Run script] [INFO]: Evaluating rate data split by random split
[2025-07-14 01:14:24] [classifiers] [INFO]: Running classifier pipeline for : dict_keys(['LogisticRegression', 'MultinomialNB', 'RandomForestClassifier', 'XGBClassifier'])
[2025-07-14 01:14:24] [classifiers] [INFO]: Tuning models on thresholds: [0.01, 0.02, 0.03], target column: pcs/m and split by: {'method': 'random', 'test_size': 0.2}
[2025-07-14 01:14:24] [classifiers] [INFO]: Full evaluation on the range of 0.01 - 1.6400000000000001
[2025-07-14 01:14:24] [classifiers] [INFO]: Tuning models for classification.
[2025-07-14 01:14:24] [classifiers] [INFO]: Tuning model: LogisticRegression
[2025-07-14 01:14:24] [classifiers] [INFO]: Threshold 0.01, AUC: 0.676, Params: {'clf__C': 0.01}
[2025-07-14 01:14:24] [classifiers] [INFO]: Threshold 0.02, AUC: 0.671, Params: {'clf__C': 0.01}
[2025-07-14 01:14:24] [classifiers] [INFO]: Threshold 0.03, AUC: 0.660, Params: {'clf__C': 0.01}
[2025-07-14 01:14:24] [classifiers] [INFO]: Tuning model: MultinomialNB
[2025-07-14 01:14:24] [classifiers] [INFO]: Threshold 0.01, AUC: 0.676, Params: {'clf__alpha': 0.1}
[2025-07-14 01:14:24] [classifiers] [INFO]: Threshold 0.02, AUC: 0.671, Params: {'clf__alpha': 0.1}
[2025-07-14 01:14:25] [classifiers] [INFO]: Threshold 0.03, AUC: 0.660, Params: {'clf__alpha': 0.1}
[2025-07-14 01:14:25] [classifiers] [INFO]: Tuning model: RandomForestClassifier
[2025-07-14 01:14:26] [classifiers] [INFO]: Threshold 0.01, AUC: 0.676, Params: {'clf__max_depth': 4, 'clf__n_estimators': 100}
[2025-07-14 01:14:28] [classifiers] [INFO]: Threshold 0.02, AUC: 0.671, Params: {'clf__max_depth': 4, 'clf__n_estimators': 100}
[2025-07-14 01:14:29] [classifiers] [INFO]: Threshold 0.03, AUC: 0.660, Params: {'clf__max_depth': 4, 'clf__n_estimators': 100}
[2025-07-14 01:14:29] [classifiers] [INFO]: Tuning model: XGBClassifier
[2025-07-14 01:14:30] [classifiers] [INFO]: Threshold 0.01, AUC: 0.676, Params: {'clf__max_depth': 3, 'clf__n_estimators': 100, 'clf__scale_pos_weight': 1}
[2025-07-14 01:14:31] [classifiers] [INFO]: Threshold 0.02, AUC: 0.671, Params: {'clf__max_depth': 3, 'clf__n_estimators': 100, 'clf__scale_pos_weight': 1}
[2025-07-14 01:14:31] [classifiers] [INFO]: Threshold 0.03, AUC: 0.660, Params: {'clf__max_depth': 3, 'clf__n_estimators': 100, 'clf__scale_pos_weight': 1}
[2025-07-14 01:14:31] [classifiers] [INFO]: Saved tuning_summary to data/test_results/random_split_pcs_m_tuning_summary.csv.
[2025-07-14 01:14:31] [classifiers] [INFO]: Summary results for tuning:
|    | model                  |     0.01 |     0.02 |     0.03 |
|---:|:-----------------------|---------:|---------:|---------:|
|  0 | LogisticRegression     | 0.676008 | 0.670683 | 0.659615 |
|  1 | MultinomialNB          | 0.676008 | 0.670683 | 0.659615 |
|  2 | RandomForestClassifier | 0.676008 | 0.670683 | 0.659615 |
|  3 | XGBClassifier          | 0.676008 | 0.670683 | 0.659615 |
[2025-07-14 01:14:31] [classifiers] [INFO]: Saving results to data/test_results
[2025-07-14 01:14:31] [classifiers] [INFO]: Selecting best model
[2025-07-14 01:14:31] [classifiers] [INFO]: Selected model: LogisticRegression with params {'C': 0.01}
[2025-07-14 01:14:31] [classifiers] [INFO]: Applying model to each threshold
[2025-07-14 01:14:31] [classifiers] [INFO]: Evaluating model: <class 'sklearn.linear_model._logistic.LogisticRegression'>
[2025-07-14 01:14:36] [classifiers] [WARNING]: Threshold 1.57: not enough class variation.
[2025-07-14 01:14:36] [classifiers] [WARNING]: Threshold 1.58: not enough class variation.
[2025-07-14 01:14:36] [classifiers] [WARNING]: Threshold 1.59: not enough class variation.
[2025-07-14 01:14:36] [classifiers] [WARNING]: Threshold 1.6: not enough class variation.
[2025-07-14 01:14:36] [classifiers] [WARNING]: Threshold 1.61: not enough class variation.
[2025-07-14 01:14:36] [classifiers] [WARNING]: Threshold 1.62: not enough class variation.
[2025-07-14 01:14:36] [classifiers] [WARNING]: Threshold 1.6300000000000001: not enough class variation.
[2025-07-14 01:14:36] [classifiers] [WARNING]: Threshold 1.6400000000000001: not enough class variation.
[2025-07-14 01:14:36] [classifiers] [INFO]: Summarizing region-level probabilities
[2025-07-14 01:14:37] [classifiers] [INFO]: The first rows of the regional predictions dataframe, number of rows = 156
 |     |   threshold |   weighted_mean_probability |      auc |   accuracy |   Grand lac |   Haut lac |   Petit lac |
|----:|------------:|----------------------------:|---------:|-----------:|------------:|-----------:|------------:|
|   0 |        0.01 |                  0.486382   | 0.818627 |   0.8      |  0.464673   | 0.519416   |  0.446691   |
|   1 |        0.02 |                  0.442863   | 0.831695 |   0.528571 |  0.425524   | 0.473376   |  0.403775   |
|   2 |        0.03 |                  0.356675   | 0.805211 |   0.557143 |  0.340071   | 0.382409   |  0.32548    |
|   3 |        0.04 |                  0.313586   | 0.804847 |   0.6      |  0.297902   | 0.335862   |  0.287757   |
|   4 |        0.05 |                  0.278106   | 0.804196 |   0.628571 |  0.257865   | 0.301016   |  0.25522    |
|   5 |        0.06 |                  0.234718   | 0.734739 |   0.757143 |  0.21761    | 0.255018   |  0.213697   |
|   6 |        0.07 |                  0.227723   | 0.734739 |   0.757143 |  0.208573   | 0.248656   |  0.207401   |
|   7 |        0.08 |                  0.20974    | 0.723958 |   0.771429 |  0.19083    | 0.229939   |  0.190513   |
|   8 |        0.09 |                  0.195138   | 0.700893 |   0.8      |  0.179123   | 0.213239   |  0.177077   |
|   9 |        0.1  |                  0.184339   | 0.674569 |   0.828571 |  0.169018   | 0.201119   |  0.16802    |
|  10 |        0.11 |                  0.184339   | 0.659476 |   0.842857 |  0.169018   | 0.201119   |  0.16802    |
|  11 |        0.12 |                  0.177033   | 0.659476 |   0.842857 |  0.162937   | 0.193303   |  0.160531   |
|  12 |        0.13 |                  0.166228   | 0.6425   |   0.857143 |  0.15283    | 0.181199   |  0.151424   |
|  13 |        0.14 |                  0.148345   | 0.584699 |   0.871429 |  0.134098   | 0.163216   |  0.134481   |
|  14 |        0.15 |                  0.133886   | 0.610887 |   0.885714 |  0.121222   | 0.146717   |  0.122255   |
|  15 |        0.16 |                  0.133886   | 0.610887 |   0.885714 |  0.121222   | 0.146717   |  0.122255   |
|  16 |        0.17 |                  0.130246   | 0.610887 |   0.885714 |  0.118281   | 0.14239    |  0.119222   |
|  17 |        0.18 |                  0.108528   | 0.684807 |   0.9      |  0.0993708  | 0.117517   |  0.100637   |
|  18 |        0.19 |                  0.108528   | 0.684807 |   0.9      |  0.0993708  | 0.117517   |  0.100637   |
|  19 |        0.2  |                  0.104899   | 0.665365 |   0.914286 |  0.0963587  | 0.113287   |  0.0975294  |
|  20 |        0.21 |                  0.104899   | 0.64     |   0.928571 |  0.0963587  | 0.113287   |  0.0975294  |
|  21 |        0.22 |                  0.104899   | 0.64     |   0.928571 |  0.0963587  | 0.113287   |  0.0975294  |
|  22 |        0.23 |                  0.0940353  | 0.772727 |   0.942857 |  0.0862885  | 0.101324   |  0.0879228  |
|  23 |        0.24 |                  0.0904015  | 0.772727 |   0.942857 |  0.0832303  | 0.0971407  |  0.0847583  |
|  24 |        0.25 |                  0.0904015  | 0.772727 |   0.942857 |  0.0832303  | 0.0971407  |  0.0847583  |
|  25 |        0.26 |                  0.0831381  | 0.772727 |   0.942857 |  0.0770632  | 0.0888308  |  0.0783865  |
|  26 |        0.27 |                  0.0795085  | 0.772727 |   0.942857 |  0.0739535  | 0.0847056  |  0.0751785  |
|  27 |        0.28 |                  0.0758804  | 0.768657 |   0.957143 |  0.0708258  | 0.080601   |  0.0719554  |
|  28 |        0.29 |                  0.0722538  | 0.768657 |   0.957143 |  0.0676795  | 0.0765174  |  0.0687168  |
|  29 |        0.3  |                  0.0686287  | 0.768657 |   0.957143 |  0.0645143  | 0.0724554  |  0.0654622  |
|  30 |        0.31 |                  0.0613752  | 0.768657 |   0.957143 |  0.0579944  | 0.0648189  |  0.0582375  |
|  31 |        0.32 |                  0.0613752  | 0.768657 |   0.957143 |  0.0579944  | 0.0648189  |  0.0582375  |
|  32 |        0.33 |                  0.0577349  | 0.768657 |   0.957143 |  0.0547556  | 0.0607882  |  0.0549366  |
|  33 |        0.34 |                  0.0577349  | 0.768657 |   0.957143 |  0.0547556  | 0.0607882  |  0.0549366  |
|  34 |        0.35 |                  0.0577349  | 0.768657 |   0.957143 |  0.0547556  | 0.0607882  |  0.0549366  |
|  35 |        0.36 |                  0.0541135  | 0.768657 |   0.957143 |  0.0515143  | 0.0567922  |  0.0516456  |
|  36 |        0.37 |                  0.050539   | 0.768657 |   0.957143 |  0.0477391  | 0.0532121  |  0.0482608  |
|  37 |        0.38 |                  0.050539   | 0.768657 |   0.957143 |  0.0477391  | 0.0532121  |  0.0482608  |
|  38 |        0.39 |                  0.050539   | 0.768657 |   0.957143 |  0.0477391  | 0.0532121  |  0.0482608  |
|  39 |        0.4  |                  0.0469171  | 0.768657 |   0.957143 |  0.0444886  | 0.0492374  |  0.0449377  |
|  40 |        0.41 |                  0.0432997  | 0.768657 |   0.957143 |  0.0412081  | 0.0452913  |  0.0416073  |
|  41 |        0.42 |                  0.0432997  | 0.768657 |   0.957143 |  0.0412081  | 0.0452913  |  0.0416073  |
|  42 |        0.43 |                  0.0432997  | 0.768657 |   0.957143 |  0.0412081  | 0.0452913  |  0.0416073  |
|  43 |        0.44 |                  0.0432997  | 0.768657 |   0.957143 |  0.0412081  | 0.0452913  |  0.0416073  |
|  44 |        0.45 |                  0.0432997  | 0.768657 |   0.957143 |  0.0412081  | 0.0452913  |  0.0416073  |
|  45 |        0.46 |                  0.0432997  | 0.768657 |   0.957143 |  0.0412081  | 0.0452913  |  0.0416073  |
|  46 |        0.47 |                  0.0396958  | 0.768657 |   0.957143 |  0.0379314  | 0.0413765  |  0.0382669  |
|  47 |        0.48 |                  0.0396958  | 0.768657 |   0.957143 |  0.0379314  | 0.0413765  |  0.0382669  |
|  48 |        0.49 |                  0.0396958  | 0.768657 |   0.957143 |  0.0379314  | 0.0413765  |  0.0382669  |
|  49 |        0.5  |                  0.0396958  | 0.768657 |   0.957143 |  0.0379314  | 0.0413765  |  0.0382669  |
|  50 |        0.51 |                  0.0396958  | 0.768657 |   0.957143 |  0.0379314  | 0.0413765  |  0.0382669  |
|  51 |        0.52 |                  0.0396958  | 0.768657 |   0.957143 |  0.0379314  | 0.0413765  |  0.0382669  |
|  52 |        0.53 |                  0.0396958  | 0.768657 |   0.957143 |  0.0379314  | 0.0413765  |  0.0382669  |
|  53 |        0.54 |                  0.0396958  | 0.764706 |   0.971429 |  0.0379314  | 0.0413765  |  0.0382669  |
|  54 |        0.55 |                  0.0396958  | 0.764706 |   0.971429 |  0.0379314  | 0.0413765  |  0.0382669  |
|  55 |        0.56 |                  0.036075   | 0.764706 |   0.971429 |  0.0346052  | 0.0374732  |  0.0348881  |
|  56 |        0.57 |                  0.036075   | 0.764706 |   0.971429 |  0.0346052  | 0.0374732  |  0.0348881  |
|  57 |        0.58 |                  0.036075   | 0.764706 |   0.971429 |  0.0346052  | 0.0374732  |  0.0348881  |
|  58 |        0.59 |                  0.036075   | 0.764706 |   0.971429 |  0.0346052  | 0.0374732  |  0.0348881  |
|  59 |        0.6  |                  0.036075   | 0.764706 |   0.971429 |  0.0346052  | 0.0374732  |  0.0348881  |
|  60 |        0.61 |                  0.036075   | 0.764706 |   0.971429 |  0.0346052  | 0.0374732  |  0.0348881  |
|  61 |        0.62 |                  0.0252262  | 0.764706 |   0.971429 |  0.0244877  | 0.0259272  |  0.0246323  |
|  62 |        0.63 |                  0.0252262  | 0.764706 |   0.971429 |  0.0244877  | 0.0259272  |  0.0246323  |
|  63 |        0.64 |                  0.0252262  | 0.764706 |   0.971429 |  0.0244877  | 0.0259272  |  0.0246323  |
|  64 |        0.65 |                  0.0252262  | 0.764706 |   0.971429 |  0.0244877  | 0.0259272  |  0.0246323  |
|  65 |        0.66 |                  0.0252262  | 0.764706 |   0.971429 |  0.0244877  | 0.0259272  |  0.0246323  |
|  66 |        0.67 |                  0.0252262  | 0.764706 |   0.971429 |  0.0244877  | 0.0259272  |  0.0246323  |
|  67 |        0.68 |                  0.0252262  | 0.764706 |   0.971429 |  0.0244877  | 0.0259272  |  0.0246323  |
|  68 |        0.69 |                  0.0252262  | 0.764706 |   0.971429 |  0.0244877  | 0.0259272  |  0.0246323  |
|  69 |        0.7  |                  0.0252262  | 0.764706 |   0.971429 |  0.0244877  | 0.0259272  |  0.0246323  |
|  70 |        0.71 |                  0.0252262  | 0.764706 |   0.971429 |  0.0244877  | 0.0259272  |  0.0246323  |
|  71 |        0.72 |                  0.0252262  | 0.764706 |   0.971429 |  0.0244877  | 0.0259272  |  0.0246323  |
|  72 |        0.73 |                  0.0252262  | 0.764706 |   0.971429 |  0.0244877  | 0.0259272  |  0.0246323  |
|  73 |        0.74 |                  0.0252262  | 0.764706 |   0.971429 |  0.0244877  | 0.0259272  |  0.0246323  |
|  74 |        0.75 |                  0.0252262  | 0.764706 |   0.971429 |  0.0244877  | 0.0259272  |  0.0246323  |
|  75 |        0.76 |                  0.0252262  | 0.764706 |   0.971429 |  0.0244877  | 0.0259272  |  0.0246323  |
|  76 |        0.77 |                  0.0252262  | 0.764706 |   0.971429 |  0.0244877  | 0.0259272  |  0.0246323  |
|  77 |        0.78 |                  0.0252262  | 0.764706 |   0.971429 |  0.0244877  | 0.0259272  |  0.0246323  |
|  78 |        0.79 |                  0.0252262  | 0.764706 |   0.971429 |  0.0244877  | 0.0259272  |  0.0246323  |
|  79 |        0.8  |                  0.0252262  | 0.764706 |   0.971429 |  0.0244877  | 0.0259272  |  0.0246323  |
|  80 |        0.81 |                  0.0252262  | 0.764706 |   0.971429 |  0.0244877  | 0.0259272  |  0.0246323  |
|  81 |        0.82 |                  0.0216171  | 0.764706 |   0.971429 |  0.0210706  | 0.0221355  |  0.0211783  |
|  82 |        0.83 |                  0.0180106  | 0.764706 |   0.971429 |  0.0176283  | 0.0183729  |  0.0177042  |
|  83 |        0.84 |                  0.0144077  | 0.764706 |   0.971429 |  0.0141613  | 0.0146412  |  0.0142104  |
|  84 |        0.85 |                  0.0144077  | 0.764706 |   0.971429 |  0.0141613  | 0.0146412  |  0.0142104  |
|  85 |        0.86 |                  0.0144077  | 0.764706 |   0.971429 |  0.0141613  | 0.0146412  |  0.0142104  |
|  86 |        0.87 |                  0.0144077  | 0.764706 |   0.971429 |  0.0141613  | 0.0146412  |  0.0142104  |
|  87 |        0.88 |                  0.0144077  | 0.764706 |   0.971429 |  0.0141613  | 0.0146412  |  0.0142104  |
|  88 |        0.89 |                  0.0144077  | 0.764706 |   0.971429 |  0.0141613  | 0.0146412  |  0.0142104  |
|  89 |        0.9  |                  0.0144077  | 0.764706 |   0.971429 |  0.0141613  | 0.0146412  |  0.0142104  |
|  90 |        0.91 |                  0.0144077  | 0.764706 |   0.971429 |  0.0141613  | 0.0146412  |  0.0142104  |
|  91 |        0.92 |                  0.0144077  | 0.764706 |   0.971429 |  0.0141613  | 0.0146412  |  0.0142104  |
|  92 |        0.93 |                  0.0144077  | 0.764706 |   0.971429 |  0.0141613  | 0.0146412  |  0.0142104  |
|  93 |        0.94 |                  0.010812   | 0.764706 |   0.971429 |  0.010672   | 0.0109445  |  0.0107     |
|  94 |        0.95 |                  0.010812   | 0.764706 |   0.971429 |  0.010672   | 0.0109445  |  0.0107     |
|  95 |        0.96 |                  0.010812   | 0.764706 |   0.971429 |  0.010672   | 0.0109445  |  0.0107     |
|  96 |        0.97 |                  0.010812   | 0.764706 |   0.971429 |  0.010672   | 0.0109445  |  0.0107     |
|  97 |        0.98 |                  0.010812   | 0.764706 |   0.971429 |  0.010672   | 0.0109445  |  0.0107     |
|  98 |        0.99 |                  0.010812   | 0.764706 |   0.971429 |  0.010672   | 0.0109445  |  0.0107     |
|  99 |        1    |                  0.010812   | 0.764706 |   0.971429 |  0.010672   | 0.0109445  |  0.0107     |
| 100 |        1.01 |                  0.010812   | 0.76087  |   0.985714 |  0.010672   | 0.0109445  |  0.0107     |
| 101 |        1.02 |                  0.010812   | 0.76087  |   0.985714 |  0.010672   | 0.0109445  |  0.0107     |
| 102 |        1.03 |                  0.010812   | 0.76087  |   0.985714 |  0.010672   | 0.0109445  |  0.0107     |
| 103 |        1.04 |                  0.010812   | 0.76087  |   0.985714 |  0.010672   | 0.0109445  |  0.0107     |
| 104 |        1.05 |                  0.010812   | 0.76087  |   0.985714 |  0.010672   | 0.0109445  |  0.0107     |
| 105 |        1.06 |                  0.010812   | 0.76087  |   0.985714 |  0.010672   | 0.0109445  |  0.0107     |
| 106 |        1.07 |                  0.010812   | 0.76087  |   0.985714 |  0.010672   | 0.0109445  |  0.0107     |
| 107 |        1.08 |                  0.010812   | 0.76087  |   0.985714 |  0.010672   | 0.0109445  |  0.0107     |
| 108 |        1.09 |                  0.010812   | 0.76087  |   0.985714 |  0.010672   | 0.0109445  |  0.0107     |
| 109 |        1.1  |                  0.010812   | 0.76087  |   0.985714 |  0.010672   | 0.0109445  |  0.0107     |
| 110 |        1.11 |                  0.010812   | 0.76087  |   0.985714 |  0.010672   | 0.0109445  |  0.0107     |
| 111 |        1.12 |                  0.010812   | 0.76087  |   0.985714 |  0.010672   | 0.0109445  |  0.0107     |
| 112 |        1.13 |                  0.010812   | 0.76087  |   0.985714 |  0.010672   | 0.0109445  |  0.0107     |
| 113 |        1.14 |                  0.010812   | 0.76087  |   0.985714 |  0.010672   | 0.0109445  |  0.0107     |
| 114 |        1.15 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 115 |        1.16 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 116 |        1.17 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 117 |        1.18 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 118 |        1.19 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 119 |        1.2  |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 120 |        1.21 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 121 |        1.22 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 122 |        1.23 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 123 |        1.24 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 124 |        1.25 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 125 |        1.26 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 126 |        1.27 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 127 |        1.28 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 128 |        1.29 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 129 |        1.3  |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 130 |        1.31 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 131 |        1.32 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 132 |        1.33 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 133 |        1.34 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 134 |        1.35 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 135 |        1.36 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 136 |        1.37 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 137 |        1.38 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 138 |        1.39 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 139 |        1.4  |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 140 |        1.41 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 141 |        1.42 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 142 |        1.43 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 143 |        1.44 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 144 |        1.45 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 145 |        1.46 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 146 |        1.47 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 147 |        1.48 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 148 |        1.49 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 149 |        1.5  |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 150 |        1.51 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 151 |        1.52 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 152 |        1.53 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 153 |        1.54 |                  0.00723463 | 0.76087  |   0.985714 |  0.00717141 | 0.0072947  |  0.0071837  |
| 154 |        1.55 |                  0.00361018 | 0.76087  |   0.985714 |  0.00359435 | 0.00362543 |  0.00359704 |
| 155 |        1.56 |                  0.00361018 | 0.76087  |   0.985714 |  0.00359435 | 0.00362543 |  0.00359704 |
[2025-07-14 01:14:37] [classifiers] [INFO]: Saved summary to data/test_results/random_split_pcs_m_summary.csv.
[2025-07-14 01:14:37] [classifiers] [INFO]: Saved test_predictions to data/test_results/random_split_pcs_m_test_predictions.csv.
[2025-07-14 01:14:37] [Run script] [INFO]: Evaluating rate data split by date
[2025-07-14 01:14:37] [classifiers] [INFO]: Running classifier pipeline for : dict_keys(['LogisticRegression', 'MultinomialNB', 'RandomForestClassifier', 'XGBClassifier'])
[2025-07-14 01:14:37] [classifiers] [INFO]: Tuning models on thresholds: [0.01, 0.02, 0.03], target column: pcs/m and split by: {'method': 'date', 'date_column': 'date', 'date_split': '2022-01-01'}
[2025-07-14 01:14:37] [classifiers] [INFO]: Full evaluation on the range of 0.01 - 1.6400000000000001
[2025-07-14 01:14:37] [classifiers] [INFO]: Tuning models for classification.
[2025-07-14 01:14:37] [classifiers] [INFO]: Tuning model: LogisticRegression
[2025-07-14 01:14:37] [classifiers] [INFO]: Threshold 0.01, AUC: 0.679, Params: {'clf__C': 0.01}
[2025-07-14 01:14:37] [classifiers] [INFO]: Threshold 0.02, AUC: 0.714, Params: {'clf__C': 0.01}
[2025-07-14 01:14:37] [classifiers] [INFO]: Threshold 0.03, AUC: 0.662, Params: {'clf__C': 0.01}
[2025-07-14 01:14:37] [classifiers] [INFO]: Tuning model: MultinomialNB
[2025-07-14 01:14:38] [classifiers] [INFO]: Threshold 0.01, AUC: 0.679, Params: {'clf__alpha': 0.1}
[2025-07-14 01:14:38] [classifiers] [INFO]: Threshold 0.02, AUC: 0.714, Params: {'clf__alpha': 0.1}
[2025-07-14 01:14:38] [classifiers] [INFO]: Threshold 0.03, AUC: 0.662, Params: {'clf__alpha': 0.1}
[2025-07-14 01:14:38] [classifiers] [INFO]: Tuning model: RandomForestClassifier
[2025-07-14 01:14:39] [classifiers] [INFO]: Threshold 0.01, AUC: 0.711, Params: {'clf__max_depth': None, 'clf__n_estimators': 100}
[2025-07-14 01:14:41] [classifiers] [INFO]: Threshold 0.02, AUC: 0.714, Params: {'clf__max_depth': 4, 'clf__n_estimators': 100}
[2025-07-14 01:14:43] [classifiers] [INFO]: Threshold 0.03, AUC: 0.662, Params: {'clf__max_depth': 4, 'clf__n_estimators': 100}
[2025-07-14 01:14:43] [classifiers] [INFO]: Tuning model: XGBClassifier
[2025-07-14 01:14:43] [classifiers] [INFO]: Threshold 0.01, AUC: 0.679, Params: {'clf__max_depth': 3, 'clf__n_estimators': 100, 'clf__scale_pos_weight': 1}
[2025-07-14 01:14:44] [classifiers] [INFO]: Threshold 0.02, AUC: 0.714, Params: {'clf__max_depth': 3, 'clf__n_estimators': 100, 'clf__scale_pos_weight': 1}
[2025-07-14 01:14:44] [classifiers] [INFO]: Threshold 0.03, AUC: 0.662, Params: {'clf__max_depth': 3, 'clf__n_estimators': 100, 'clf__scale_pos_weight': 1}
[2025-07-14 01:14:44] [classifiers] [INFO]: Saved tuning_summary to data/test_results/date_split_pcs_m_tuning_summary.csv.
[2025-07-14 01:14:44] [classifiers] [INFO]: Summary results for tuning:
|    | model                  |     0.01 |     0.02 |     0.03 |
|---:|:-----------------------|---------:|---------:|---------:|
|  0 | LogisticRegression     | 0.678854 | 0.713885 | 0.662093 |
|  1 | MultinomialNB          | 0.678854 | 0.713885 | 0.662093 |
|  2 | RandomForestClassifier | 0.711321 | 0.713885 | 0.662093 |
|  3 | XGBClassifier          | 0.678854 | 0.713885 | 0.662093 |
[2025-07-14 01:14:44] [classifiers] [INFO]: Saving results to data/test_results
[2025-07-14 01:14:44] [classifiers] [INFO]: Selecting best model
[2025-07-14 01:14:44] [classifiers] [INFO]: Selected model: RandomForestClassifier with params {'max_depth': 4, 'n_estimators': 100}
[2025-07-14 01:14:44] [classifiers] [INFO]: Applying model to each threshold
[2025-07-14 01:14:44] [classifiers] [INFO]: Evaluating model: <class 'sklearn.ensemble._forest.RandomForestClassifier'>
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.37: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.38: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.39: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.4: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.41000000000000003: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.42000000000000004: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.43: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.44: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.45: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.46: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.47000000000000003: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.48000000000000004: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.49: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.5: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.51: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.52: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.53: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.54: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.55: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.56: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.5700000000000001: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.5800000000000001: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.59: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.6: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.61: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.62: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.63: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.64: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.65: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.66: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.67: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.68: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.6900000000000001: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.7000000000000001: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.7100000000000001: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.72: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.73: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.74: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.75: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.76: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.77: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.78: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.79: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.8: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.81: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.8200000000000001: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.8300000000000001: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.8400000000000001: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.85: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.86: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.87: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.88: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.89: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.9: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.91: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.92: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.93: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.9400000000000001: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.9500000000000001: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.9600000000000001: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.97: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.98: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 0.99: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.0: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.01: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.02: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.03: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.04: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.05: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.06: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.07: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.08: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.09: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.1: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.11: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.12: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.1300000000000001: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.1400000000000001: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.1500000000000001: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.1600000000000001: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.17: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.18: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.19: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.2: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.21: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.22: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.23: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.24: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.25: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.26: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.27: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.28: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.29: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.3: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.31: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.32: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.33: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.34: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.35: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.36: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.37: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.3800000000000001: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.3900000000000001: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.4000000000000001: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.4100000000000001: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.42: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.43: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.44: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.45: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.46: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.47: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.48: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.49: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.5: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.51: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.52: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.53: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.54: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.55: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.56: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.57: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.58: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.59: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.6: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.61: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.62: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.6300000000000001: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [WARNING]: Threshold 1.6400000000000001: not enough class variation.
[2025-07-14 01:14:52] [classifiers] [INFO]: Summarizing region-level probabilities
[2025-07-14 01:14:53] [classifiers] [INFO]: The first rows of the regional predictions dataframe, number of rows = 36
 |    |   threshold |   weighted_mean_probability |      auc |   accuracy |   Grand lac |   Haut lac |   Petit lac |
|---:|------------:|----------------------------:|---------:|-----------:|------------:|-----------:|------------:|
|  0 |        0.01 |                   0.428561  | 0.617007 |   0.622449 |   0.376046  |   0.7288   |   0.253098  |
|  1 |        0.02 |                   0.408276  | 0.573552 |   0.622449 |   0.379618  |   0.698322 |   0.200342  |
|  2 |        0.03 |                   0.336032  | 0.558612 |   0.653061 |   0.31343   |   0.593551 |   0.146471  |
|  3 |        0.04 |                   0.283981  | 0.587941 |   0.663265 |   0.232841  |   0.540906 |   0.144624  |
|  4 |        0.05 |                   0.242527  | 0.545493 |   0.673469 |   0.168955  |   0.525707 |   0.118882  |
|  5 |        0.06 |                   0.190039  | 0.555682 |   0.897959 |   0.124459  |   0.431249 |   0.0897872 |
|  6 |        0.07 |                   0.197784  | 0.563889 |   0.918367 |   0.13909   |   0.427416 |   0.0958385 |
|  7 |        0.08 |                   0.176964  | 0.627943 |   0.928571 |   0.109392  |   0.402784 |   0.0938592 |
|  8 |        0.09 |                   0.159556  | 0.627943 |   0.928571 |   0.101113  |   0.372375 |   0.0721182 |
|  9 |        0.1  |                   0.15348   | 0.592473 |   0.94898  |   0.104363  |   0.346092 |   0.06777   |
| 10 |        0.11 |                   0.150255  | 0.592473 |   0.94898  |   0.0984597 |   0.342503 |   0.0695289 |
| 11 |        0.12 |                   0.147084  | 0.592473 |   0.94898  |   0.101484  |   0.340356 |   0.0546664 |
| 12 |        0.13 |                   0.131274  | 0.592473 |   0.94898  |   0.0865314 |   0.308746 |   0.0514083 |
| 13 |        0.14 |                   0.111687  | 0.640351 |   0.969388 |   0.0646725 |   0.291856 |   0.0333757 |
| 14 |        0.15 |                   0.0960943 | 0.640351 |   0.969388 |   0.0522311 |   0.273471 |   0.0147805 |
| 15 |        0.16 |                   0.0975144 | 0.640351 |   0.969388 |   0.0529177 |   0.277815 |   0.0148788 |
| 16 |        0.17 |                   0.0957862 | 0.640351 |   0.969388 |   0.0516026 |   0.2695   |   0.0182865 |
| 17 |        0.18 |                   0.0784451 | 0.700521 |   0.979592 |   0.0332494 |   0.235454 |   0.0175557 |
| 18 |        0.19 |                   0.0783932 | 0.700521 |   0.979592 |   0.0339984 |   0.233299 |   0.0179789 |
| 19 |        0.2  |                   0.0745927 | 0.700521 |   0.979592 |   0.0346835 |   0.215158 |   0.0191175 |
| 20 |        0.21 |                   0.0746759 | 0.700521 |   0.979592 |   0.0348802 |   0.214812 |   0.0193842 |
| 21 |        0.22 |                   0.0722391 | 0.700521 |   0.979592 |   0.0304432 |   0.211753 |   0.0209825 |
| 22 |        0.23 |                   0.0515885 | 0.559896 |   0.979592 |   0         |   0.188832 |   0.0193964 |
| 23 |        0.24 |                   0.0520139 | 0.559896 |   0.979592 |   0         |   0.189183 |   0.0206286 |
| 24 |        0.25 |                   0.0519264 | 0.559896 |   0.979592 |   0         |   0.192227 |   0.0176052 |
| 25 |        0.26 |                   0.0475823 | 0.559896 |   0.979592 |   0         |   0.173581 |   0.0184118 |
| 26 |        0.27 |                   0.0469574 | 0.559896 |   0.979592 |   0         |   0.169322 |   0.0199295 |
| 27 |        0.28 |                   0.0430809 | 0.559896 |   0.979592 |   0         |   0.155611 |   0.018047  |
| 28 |        0.29 |                   0.0421881 | 0.559896 |   0.979592 |   0         |   0.149002 |   0.0206808 |
| 29 |        0.3  |                   0.0409744 | 0.237113 |   0.989796 |   0         |   0.147251 |   0.0178318 |
| 30 |        0.31 |                   0.0334979 | 0.376289 |   0.989796 |   0         |   0.136783 |   0         |
| 31 |        0.32 |                   0.0341547 | 0.376289 |   0.989796 |   0         |   0.139465 |   0         |
| 32 |        0.33 |                   0.0334532 | 0.376289 |   0.989796 |   0         |   0.136601 |   0         |
| 33 |        0.34 |                   0.0325838 | 0.376289 |   0.989796 |   0         |   0.13305  |   0         |
| 34 |        0.35 |                   0.0315581 | 0.376289 |   0.989796 |   0         |   0.128862 |   0         |
| 35 |        0.36 |                   0.02996   | 0.376289 |   0.989796 |   0         |   0.122336 |   0         |
[2025-07-14 01:14:53] [classifiers] [INFO]: Saved summary to data/test_results/date_split_pcs_m_summary.csv.
[2025-07-14 01:14:53] [classifiers] [INFO]: Saved test_predictions to data/test_results/date_split_pcs_m_test_predictions.csv.
[2025-07-14 01:14:53] [Run script] [INFO]: End evaluation
